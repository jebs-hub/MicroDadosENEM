{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jebs-hub/MicroDadosENEM/blob/main/code-pt/MicroDadosEnemAn%C3%A1lise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visão geral\n",
        "\n",
        "Com o objetivo de aprender a manipular dados com a biblioteca `Pandas`, foi feita uma análise dos dados do ENEM para responder duas perguntas principais:\n",
        "- Porcentagem de acertos por questão e o quanto isso reflete no nível de dificuldade prévio de cada questão\n",
        "- Quantidade de acertos por nota, para que seja possível estabelecer uma relação entre essas grandezas e observar valores atípicos.\n",
        "\n",
        "## Entendendo o ENEM e o banco\n",
        "ENEM é sigla para EXAME Nacional do Ensino Médio.\n",
        "Como o próprio nome já diz, consiste em uma prova realizada todos os anos pelo governo brasileiro para avaliar o conhecimento de alunos que estão se formando no Ensino Médio. \n",
        "A prova é composta por 4 áreas do conhecimento:\n",
        "- Ciências Humanas e suas tecnologias\n",
        "- Ciências da Natureza e suas tecnologias\n",
        "- Linguagens, Códigos e suas tecnologias\n",
        "- Matemática e suas tecnologias\n",
        "- Redação\n",
        "\n",
        "Com exceção de Redação, até a edição de 2022, as provas foram de múltipla escolha. A nota é atribuída com base no sistema de [TRI](https://gauchazh.clicrbs.com.br/educacao-e-emprego/noticia/2021/11/como-funciona-a-tri-na-avaliacao-do-enem-ckw3zwd9c004a016fuvd3uu6k.html). Assim duas pessoas com o mesmo número de acertos não necessariamente tiram a mesma nota. De acordo com o funcionamento da TRI, acertar questões mais fáceis somam mais pontos para nota final, do que acertar questões difíceis. \n",
        "\n",
        "## O problema\n",
        "Com base nisso, questões muito relevantes emergem entre estudantes:\n",
        "- Quais as questões mais fáceis, e portanto, as que devo acertar mais?\n",
        "- Qual a relação média de acertos x notas?\n",
        "- Quantas questões preciso acertar para que minha nota fique entre X e Y?\n",
        "\n",
        "A única base da dados a qual temos acesso são os [Microdados do ENEM](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem). O documento contém informações sobre os editais, os métodos aplicados para avaliação da TRI e informações de inscritos, tais como informações socioeconômicas, o código e cor da prova realizada por cada inscrito, bem como seu gabarito e a nota correspondente (ambas em uma string. Ex: \"ABBBDE..\"). \n",
        "Dada a dimensão nacional da prova, os dados são muito extensos, chegando a 5 milhões de linhas.\n",
        "Além disso, existe um arquivo menor com dados referentes às questões, que informam o código da questão, em quais provas ela aparece e em que ordem ela aparece, seu nível de dificuldade (usado pelo TRI para atribuir nota),entre outros parâmetros.\n",
        "Todavia, não há respostas diretas para as perguntas mencionadas acima. \n",
        "Esse nootebook contém um código justamente para fazer essa análise e trazer respostas. \n",
        "\n",
        "## Funcionamento do código\n",
        "As operações principais realizadas por esse código são:\n",
        "1) Filtrar somente estudantes que fizeram as 5 provas com coerência, isto é, não zeraram, faltaram ou anularam nenhuma prova. \n",
        "2) Para cada estudante, comparar as strings de gabarito e de resposta para contabilizar a quantidade de acertos e contabilizar a quantidade de acertos de cada questão.\n",
        "3) Ordenar questões com base na porcentagem para listas as mais fáceis e mais difíceis.\n",
        "4) Construir histogramas e gráficos para analisar a relação de acertos e notas, com isso, buscar acertos mínimos e máximos para uma nota alvo, ou fazendo o processo contrário, buscar notas máximas e mínimas para um número de acertos alvo. \n",
        "5) Por fim, análises secundárias para o propósito desse projeto podem ser feitas: relação entre nota e nível socioenconômico, ano de formação no ensino médio, entre outros parâmetros.\n",
        "\n",
        "A estrutura do que deve ser feito em si é simples. A maior dificuldade encontrada foi como organizar e padronizar todos os dados. Uma mesma provas tem várias versões, com questões em ordens diferentes. Logo, para duas respostas de dois alunos, \"AABBB..\" e \"ACDDEA..\", não significa que as questões na posição 0 da string sejam as mesmas, as provas podem ter cores diferentes e isso deve ser checado a cada contagem. \n",
        "Além disso, há casos em que, por motivos de desastres e demais problemas no dia da aplicação, a prova é aplicada em outro dia, então há duas provas com conjunto de questões totalmente diferentes e sem intersecção nenhuma. Outros detalhes, mais específicos foram surgindo e tiveram que ser tratados, como a opção pela língua espanhol ou inglês nas provas, que afeta o formato da string de resposta. \n",
        "\n",
        "## Saídas\n",
        "\n",
        "Publiquei [planilhas](https://drive.google.com/drive/folders/1yVT-PJZ7oHBNL1bGHtw22vdQh4r-DzYS?usp=sharing) com gráficos e resultados mais interessantes do ponto de vista das pessoas que estão se preparando para a prova. O acesso a elas é livre.\n",
        "\n",
        "Publiquei um [vídeo](https://www.youtube.com/watch?v=gUJe4yOGFLM) mostrando as análises. Não é um tutorial para o desenvolvimento do código! Mas explica o que foi feito, como funcionam os dados, mostra os dados finais sendo explorados e mostra como usar a planilha criada.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QdLnPsoHd9D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração inicial\n",
        "Importando bibliotecas, lendo dados e ordenando vetores."
      ],
      "metadata": {
        "id": "jwhHeXscrXuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r50DlXizlSp7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                    #importando bibliotecas importantes\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq0CLNTSsZaq"
      },
      "outputs": [],
      "source": [
        "#importando colunas com dados úteis e incluindo dó quem tem nota válida para todas as áreas\n",
        "fields = ['TP_ANO_CONCLUIU','TP_LINGUA', 'NU_NOTA_MT', 'TX_RESPOSTAS_MT','NU_NOTA_CN', 'TX_RESPOSTAS_CN','NU_NOTA_CH', 'TX_RESPOSTAS_CH', 'NU_NOTA_LC', 'TX_RESPOSTAS_LC', 'CO_PROVA_LC','CO_PROVA_MT','CO_PROVA_CH','CO_PROVA_CN', 'TX_GABARITO_MT', 'TX_GABARITO_LC', 'TX_GABARITO_CN', 'TX_GABARITO_CH','SG_UF_PROVA']\n",
        "dados = pd.read_csv('/content/drive/MyDrive/dados/2019/MICRODADOS_ENEM_2019.csv', sep=';', usecols=fields, encoding='latin-1', skip_blank_lines=True).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ-9X2WMzGZV"
      },
      "outputs": [],
      "source": [
        "#importar relações entre questões, provas, ID's\n",
        "infos_questoes = pd.read_csv('/content/drive/MyDrive/dados/ITENS_PROVA_2019.csv', sep=';', encoding='latin-1', skip_blank_lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMDPxJbQOayY"
      },
      "outputs": [],
      "source": [
        "infos_questoes.sort_values(['CO_ITEM','CO_PROVA'],inplace=True) #ordenando questões por item"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisando questões\n",
        "Criando estrutura para armazenar a quantidade acertos de cada questão, que será contabilizada depois.\n",
        "A estrutura é formada por vários `dicionários` , dois para cada área do conhecimento: um para número de acertos e outro para número de respondidas. As chaves são o código da prova e os valores, um vetor com 45 posições inicializadas com valor zero. A cada acerto/resposta incrementamos um no dicionário, chave e posição correspondentes."
      ],
      "metadata": {
        "id": "yETPR03troN8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHrM_8w2I_Qe"
      },
      "outputs": [],
      "source": [
        "CO_ITENS = infos_questoes['CO_ITEM'].drop_duplicates()\n",
        "ACERTOS_QUESTOES = pd.DataFrame(0,index=CO_ITENS,columns=['NU_ACERTOS','NU_RESPONDIDAS','PORCENTAGEM']) #craindo matriz para receber os acertos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMMeMqV1I2Gv"
      },
      "outputs": [],
      "source": [
        "CO_PROVAS = infos_questoes[['CO_PROVA','SG_AREA']].drop_duplicates(subset='CO_PROVA')  #criando dicionários para salvar os códigos das\n",
        "NU_RESPONDIDAS_PROVAS_LC = {}                                                          #questões e quantos acertos ela teve\n",
        "NU_RESPONDIDAS_PROVAS_CH = {}\n",
        "NU_RESPONDIDAS_PROVAS_CN = {}\n",
        "NU_RESPONDIDAS_PROVAS_MT = {}\n",
        "NU_ACERTOS_PROVAS_LC = {}\n",
        "NU_ACERTOS_PROVAS_CH = {}\n",
        "NU_ACERTOS_PROVAS_CN = {}\n",
        "NU_ACERTOS_PROVAS_MT = {}\n",
        "from pandas.io.parsers.c_parser_wrapper import is_index_col\n",
        "for index, row in CO_PROVAS.iterrows():   #para cada pessoa que fez o Enem\n",
        "  if(row['SG_AREA'] == 'LC'):\n",
        "    NU_RESPONDIDAS_PROVAS_LC[row['CO_PROVA']] = [0]*50\n",
        "    NU_ACERTOS_PROVAS_LC[row['CO_PROVA']] = [0]*50\n",
        "  elif(row['SG_AREA'] == 'CH'):\n",
        "    NU_RESPONDIDAS_PROVAS_CH[row['CO_PROVA']] = [0]*45\n",
        "    NU_ACERTOS_PROVAS_CH[row['CO_PROVA']] = [0]*45\n",
        "  elif(row['SG_AREA'] == 'CN'):\n",
        "    NU_RESPONDIDAS_PROVAS_CN[row['CO_PROVA']] = [0]*45\n",
        "    NU_ACERTOS_PROVAS_CN[row['CO_PROVA']] = [0]*45\n",
        "  elif(row['SG_AREA'] == 'MT'):\n",
        "    NU_RESPONDIDAS_PROVAS_MT[row['CO_PROVA']] = [0]*45\n",
        "    NU_ACERTOS_PROVAS_MT[row['CO_PROVA']] = [0]*45"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contando questões - o principal\n",
        "Criando um data frame para armazenar a quantidade de acertos de cada estudante por questão e por prova. \n",
        "Iteramos sobre os dados, contando e salvando valores: quantidade de acertos do estudante e quantidade de acertos da questão, \n",
        "Assim, usamos também a estrutura de questões criada anteriormente.\n",
        "Essa é a parte principal do código, o centro do que precisa ser feito."
      ],
      "metadata": {
        "id": "odkaDjOMsnRJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG9uHVXj5k0y"
      },
      "outputs": [],
      "source": [
        "ALUNOS_ACERTOS_NOTAS = pd.DataFrame(0,index=dados.index, columns=['NU_ACERTOS_LC','NU_ACERTOS_CH','NU_ACERTOS_CN','NU_ACERTOS_MT']) \n",
        "#criando colunas para salvar os acertos dos alunos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kVpnNTFrlvG"
      },
      "outputs": [],
      "source": [
        "from pandas.io.parsers.c_parser_wrapper import is_index_col                           #passando por todos os alunos e salvando os acertos\n",
        "for index, row in dados.iterrows():   #para cada pessoa que fez o Enem\n",
        "    \n",
        "    CO_PROVA_CN = row['CO_PROVA_CN']  #obtem código de cada prova que ela fez\n",
        "    CO_PROVA_MT = row['CO_PROVA_MT']\n",
        "    CO_PROVA_CH = row['CO_PROVA_CH']\n",
        "    CO_PROVA_LC = row['CO_PROVA_LC']\n",
        "    \n",
        "    NU_ACERTOS_LC = 0      #somador de quantidade de acertos\n",
        "    NU_ACERTOS_CH = 0\n",
        "    NU_ACERTOS_CN = 0\n",
        "    NU_ACERTOS_MT = 0\n",
        "\n",
        "    for i in range(0,45): #passa pelas 45 questões\n",
        "    \n",
        "      if(row['TP_LINGUA']==0 and i < 5):                          #se a língua é 1 e estamos nas primeiras 5 questoes\n",
        "        if(row['TX_RESPOSTAS_LC'][i]==row['TX_GABARITO_LC'][i]):\n",
        "          NU_ACERTOS_PROVAS_LC[int(CO_PROVA_LC)][i]+=1\n",
        "          NU_ACERTOS_LC+=1\n",
        "      else:\n",
        "        if(row['TX_RESPOSTAS_LC'][i+5]==row['TX_GABARITO_LC'][i+5]):\n",
        "          NU_ACERTOS_PROVAS_LC[int(CO_PROVA_LC)][i+5]+=1\n",
        "          NU_ACERTOS_LC+=1\n",
        "\n",
        "      if(row['TX_RESPOSTAS_CH'][i]==row['TX_GABARITO_CH'][i]):   #contabiliza acerto nas respostas em geral\n",
        "        NU_ACERTOS_PROVAS_CH[int(CO_PROVA_CH)][i]+=1              #e contabiliza acerto para aluno\n",
        "        NU_ACERTOS_CH+=1\n",
        "\n",
        "      if(row['TX_RESPOSTAS_CN'][i]==row['TX_GABARITO_CN'][i]):\n",
        "        NU_ACERTOS_PROVAS_CN[int(CO_PROVA_CN)][i]+=1\n",
        "        NU_ACERTOS_CN+=1\n",
        "\n",
        "      if(row['TX_RESPOSTAS_MT'][i]==row['TX_GABARITO_MT'][i]):\n",
        "        NU_ACERTOS_PROVAS_MT[int(CO_PROVA_MT)][i]+=1\n",
        "        NU_ACERTOS_MT+=1\n",
        "\n",
        "      if(row['TP_LINGUA'] == 1 and i < 5):                     #independnete se acertou ou não contabiliza como respondida\n",
        "        NU_RESPONDIDAS_PROVAS_LC[int(CO_PROVA_LC)][i+5]+=1       #essa relação é diferente para LC por causa das linguagens\n",
        "      elif(row['TP_LINGUA'] == 0 and i < 5):\n",
        "        NU_RESPONDIDAS_PROVAS_LC[int(CO_PROVA_LC)][i]+=1\n",
        "      else:\n",
        "        NU_RESPONDIDAS_PROVAS_LC[int(CO_PROVA_LC)][i+5]+=1\n",
        "\n",
        "      NU_RESPONDIDAS_PROVAS_CH[int(CO_PROVA_CH)][i]+=1  #relação é simples para as outras\n",
        "      NU_RESPONDIDAS_PROVAS_CN[int(CO_PROVA_CN)][i]+=1\n",
        "      NU_RESPONDIDAS_PROVAS_MT[int(CO_PROVA_MT)][i]+=1\n",
        "    \n",
        "    ALUNOS_ACERTOS_NOTAS.loc[index]['NU_ACERTOS_LC']=NU_ACERTOS_LC  #fora do for de questões atualizamos quanto o aluno acertou\n",
        "    ALUNOS_ACERTOS_NOTAS.loc[index]['NU_ACERTOS_CH']=NU_ACERTOS_CH\n",
        "    ALUNOS_ACERTOS_NOTAS.loc[index]['NU_ACERTOS_CN']=NU_ACERTOS_CN\n",
        "    ALUNOS_ACERTOS_NOTAS.loc[index]['NU_ACERTOS_MT']=NU_ACERTOS_MT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqGOBBIBFl2q"
      },
      "outputs": [],
      "source": [
        "ANALISE_NOTAS = pd.concat([dados[fields], ALUNOS_ACERTOS_NOTAS], axis=1) #concatenando resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenando resultados\n",
        "\n",
        "Com base no código da prova e na sua variação de posição por provas, vamos achar as questões correspondetes entre provas e somar os acertos e as respondidas, concatenando todos os resultados."
      ],
      "metadata": {
        "id": "5Jhzqu6ftNZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwGvgB5gY6Fe"
      },
      "outputs": [],
      "source": [
        "for CO_PROVA in NU_ACERTOS_PROVAS_LC:   #relacionando e concatenando as mesmas questões para provas diferentes\n",
        "  for i in range(0,50):\n",
        "    index = i + 1                 \n",
        "    if(i > 4):\n",
        "      index-=5                      \n",
        "    if(i<5):\n",
        "      CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) & (infos_questoes['TP_LINGUA']==0) , 'CO_ITEM'].iloc[0]\n",
        "    elif(i<10):\n",
        "      CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) & (infos_questoes['TP_LINGUA']==1) , 'CO_ITEM'].iloc[0]\n",
        "    else:\n",
        "      CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) , 'CO_ITEM'].iloc[0]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_ACERTOS'] += NU_ACERTOS_PROVAS_LC[CO_PROVA][i]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_RESPONDIDAS'] += NU_RESPONDIDAS_PROVAS_LC[CO_PROVA][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0il71UgkySC"
      },
      "outputs": [],
      "source": [
        "for CO_PROVA in NU_ACERTOS_PROVAS_CH:\n",
        "  for i in range(0,45):\n",
        "    index = i + 46\n",
        "    CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) , 'CO_ITEM'].iloc[0]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_ACERTOS'] += NU_ACERTOS_PROVAS_CH[CO_PROVA][i]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_RESPONDIDAS'] += NU_RESPONDIDAS_PROVAS_CH[CO_PROVA][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJBiDQpXlpQw"
      },
      "outputs": [],
      "source": [
        "for CO_PROVA in NU_ACERTOS_PROVAS_CN:\n",
        "  for i in range(0,45):\n",
        "    index = i + 91\n",
        "    CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) , 'CO_ITEM'].iloc[0]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_ACERTOS'] += NU_ACERTOS_PROVAS_CN[CO_PROVA][i]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_RESPONDIDAS'] += NU_RESPONDIDAS_PROVAS_CN[CO_PROVA][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFqxaMpfl0wD"
      },
      "outputs": [],
      "source": [
        "for CO_PROVA in NU_ACERTOS_PROVAS_MT:\n",
        "  for i in range(0,45):\n",
        "    index = i + 136\n",
        "    CO_ITEM = infos_questoes.loc[(infos_questoes['CO_PROVA'] == int(CO_PROVA)) & (infos_questoes['CO_POSICAO'] == index) , 'CO_ITEM'].iloc[0]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_ACERTOS'] += NU_ACERTOS_PROVAS_MT[CO_PROVA][i]\n",
        "    ACERTOS_QUESTOES.loc[CO_ITEM]['NU_RESPONDIDAS'] += NU_RESPONDIDAS_PROVAS_MT[CO_PROVA][i]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A justando e escrevendo resultado\n",
        "\n",
        "Após coletar e concatenar resultados, ajustamos e deixamos em um formato para salvar. "
      ],
      "metadata": {
        "id": "Wovu7JNQtmPq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV4uuDFHes2Y"
      },
      "outputs": [],
      "source": [
        "infos_questoes = infos_questoes.drop_duplicates(subset='CO_ITEM')  #ajustes finais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imr4Ve7gfw72"
      },
      "outputs": [],
      "source": [
        "ACERTOS_QUESTOES = ACERTOS_QUESTOES.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7bJhE6UfzoU"
      },
      "outputs": [],
      "source": [
        "infos_questoes = infos_questoes.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5P1bFAvfTUF"
      },
      "outputs": [],
      "source": [
        "ANALISE_QUESTOES = pd.concat([infos_questoes, ACERTOS_QUESTOES], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO0jmR0Gsk9z"
      },
      "outputs": [],
      "source": [
        "ANALISE_QUESTOES = ANALISE_QUESTOES.loc[:,~ANALISE_QUESTOES.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLxF6PPHgRZ8"
      },
      "outputs": [],
      "source": [
        "ANALISE_QUESTOES['PORCENTAGEM'] = ANALISE_QUESTOES['NU_ACERTOS']/ANALISE_QUESTOES['NU_RESPONDIDAS']*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcqyIwbg1KIP"
      },
      "outputs": [],
      "source": [
        "ANALISE_QUESTOES.to_csv('/content/drive/MyDrive/dados/ANALISE_QUESTOES_2019.csv', index=False)  #salvando resultado\n",
        "ANALISE_NOTAS.to_csv('/content/drive/MyDrive/dados/ANALISE_ENEM_2019.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo análises e gráficos\n",
        "Esses são alguns exemplo das respostas que querememos buscar\n",
        "\n",
        "## Variação da nota por número de acerto"
      ],
      "metadata": {
        "id": "o6WUjwQtt1K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX = ANALISE_NOTAS[ANALISE_NOTAS['NU_ACERTOS_MT']==40]['NU_NOTA_MT'].max()"
      ],
      "metadata": {
        "id": "ngrP62COuLFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN = ANALISE_NOTAS[ANALISE_NOTAS['NU_ACERTOS_MT']==40]['NU_NOTA_MT'].min()"
      ],
      "metadata": {
        "id": "5V_AfuyIuOTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN = ANALISE_NOTAS[ANALISE_NOTAS['NU_NOTA_MT']>=800]['NU_ACERTOS_MT'].idxmin()"
      ],
      "metadata": {
        "id": "1cy0leguuQlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANALISE_NOTAS.loc[MIN]"
      ],
      "metadata": {
        "id": "DN3PF5XZuS4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX - MIN"
      ],
      "metadata": {
        "id": "7zBE33t6uYVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANALISE_NOTAS[(ANALISE_NOTAS['NU_ACERTOS_MT']==42)]"
      ],
      "metadata": {
        "id": "_YRRDVuRubjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Histograma\n",
        "acertos_MT = ANALISE_NOTAS[ANALISE_NOTAS['NU_ACERTOS_MT']==25]\n",
        "notas = acertos_MT[['NU_NOTA_MT']].to_numpy()\n",
        "plt.title('Frequência de notas por acerto')\n",
        "plt.xlabel('Notas')\n",
        "plt.ylabel('Frequência Absoluta')\n",
        "plt.hist(notas, 10, rwidth=0.9)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qVudZ7f6ufIy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1LnPuJ1RnAzN7OwRAmeNjFSWRTnoWETXW",
      "authorship_tag": "ABX9TyOMFS+v2LXb/vTqNqVgiYJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}